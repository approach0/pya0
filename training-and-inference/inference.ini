[DEFAULT]
####################
# GPU Configuration
####################
devices = {
        "cpu": ["cpu", "0"],
        "cpu_debug": ["cpu", "debug"],
        "gtx1060": ["cuda:0", "6"],
        "titan_rtx": ["cuda:2", "24"],
        "a6000_0": ["cuda:0", "48"],
        "a6000_1": ["cuda:1", "48"],
        "a6000_2": ["cuda:2", "48"],
        "a6000_3": ["cuda:3", "48"],
        "a6000_4": ["cuda:4", "48"],
        "a6000_5": ["cuda:5", "48"],
        "a6000_6": ["cuda:6", "48"],
        "a6000_7": ["cuda:7", "48"],
        "rtx2080": ["cuda:0", "11"],
        "v100_0": ["cuda:0", "32"],
        "v100_1": ["cuda:1", "32"],
        "v100_2": ["cuda:2", "32"],
        "v100_3": ["cuda:3", "32"]
    }

#########
# Paths
#########
root = .
indexes = %(root)s/indexes
run_outdir = %(root)s/runs
pyserini = %(root)s/pyserini
display_frq = 100
corpus_reader_begin = 0
#corpus_reader_end = 9999
corpus_reader_end = 0

###########
# Datasets
###########
ntcir12_txt = %(root)s/datasets/NTCIR12_latex_expressions.txt
arqmath3_xml = %(root)s/datasets/Posts.V1.3.xml
arqmath3_task2_dir = %(root)s/datasets/latex_representation_v3

############
# Tokenizer
############
default_tokenizer = %(root)s/math-tokenizer

################
# Cross Encoder
################
math_10_tokenizer = AnReu/albert-for-arqmath-3
math_10_model = AnReu/albert-for-arqmath-3

#####################
# Models Checkpoints
#####################
cocomae_ckpts = %(root)s/models/job-single_vec_retriever-a6000-using-cocomae-single_vec_retriever

#################
# Index Sections
#################
[index_ntcir12_cocomae]
ckpt: 6-0-0
corpus_reader: ["ntcir12_txt", "%(ntcir12_txt)s"]
passage_encoder: ["dpr_default", "%(default_tokenizer)s", "%(cocomae_ckpts)s/{ckpt}"]
indexer: ["docid_vec_flat_faiss", "%(indexes)s/ntcir12-cocomae-{ckpt}"]
batch_map = {"0": 1, "24" : 400, "48": 1000}

##################
# Search Sections
##################
[search_ntcir12_cocomae]
ckpt: 6-0-0
passage_encoder: ["dpr_default", "%(default_tokenizer)s", "%(cocomae_ckpts)s/{ckpt}"]
searcher: ["docid_vec_flat_faiss", "%(indexes)s/ntcir12-cocomae-{ckpt}"]
topk: 1000
verbose: False
query_keyword_separator: space
topics_collection: ntcir12-math-browsing-concrete
output_format: TREC
output_id_fields: [0, 0]
output_filename: ntcir12-cocomae-{ckpt}-top{topk}.run
batch_map = {"0": 1}

#####################
# Reranking Sections
#####################
[maprun_arqmath3_to_math_10]
passage_scorer: ["math_10", "%(math_10_tokenizer)s", "%(math_10_model)s"]
verbose: False
lookup_index: docdict:%(index_dir)s/index-ColBERT-arqmath3
query_keyword_separator: space
topics_collection: arqmath-2022-task1-or-task3-origin
batch_map = {"0": 1, "debug": 2, "6": 120}
max_ql = 512
topk: 1000
filter_topics = []
max_select_sentence = 0
min_select_sentence = 0

[maprun_splade__somemath]
var_tokenizer: %(condenser_tokenizer)s
var_model: %(splade_model)s
passage_scorer: ["splade", "{var_tokenizer}", "{var_model}", 30720, "somemath"]
verbose: False
lookup_index: docdict:%(index_dir)s/index-ColBERT-arqmath3
query_keyword_separator: space
topics_collection: arqmath-2022-task1-or-task3-origin
batch_map = {"0": 1, "debug": 2, "48": 240}
topk: 1000
filter_topics = ["A.345"]
#filter_topics = []
max_select_sentence = 0
min_select_sentence = 0

#####################
# Pipeline Sections
#####################
[pipeline__eval_arqmath3_splade]
var_tokenizer: %(condenser_tokenizer)s
var_model: %(splade_model)s
commands = [
        "python -m pya0.transformer_eval maprun ./utils/transformer_eval.ini maprun_splade__somemath ./topics-and-qrels/qrels.arqmath-2022-task1-or-task3-origin.txt --input_format=qrels --device=a6000_0 --var_tokenizer={var_tokenizer} --var_model={var_model}",
        "bash ./eval-arqmath3/task1/preprocess.sh cleanup",
        "bash ./eval-arqmath3/task1/preprocess.sh ./runs/maprun_splade__somemath--qrels.arqmath-2022-task1-or-task3-origin.txt",
        "bash ./eval-arqmath3/task1/eval.sh --nojudge",
        "cat ./eval-arqmath3/task1/result.tsv"
    ]
metrics = ["arqmath"]

[pipeline__eval_arqmath3_colbert]
var_tokenizer: %(colbert_tokenizer)s
var_model: %(colbert_model)s
commands = [
        "python -m pya0.transformer_eval maprun ./utils/transformer_eval.ini maprun_arqmath3_to_colbert ./topics-and-qrels/qrels.arqmath-2022-task1-or-task3-origin.txt --input_format=qrels --device=a6000_1 --var_tokenizer={var_tokenizer} --var_model={var_model}",
        "bash ./eval-arqmath3/task1/preprocess.sh cleanup",
        "bash ./eval-arqmath3/task1/preprocess.sh ./runs/maprun_arqmath3_to_colbert--qrels.arqmath-2022-task1-or-task3-origin.txt",
        "bash ./eval-arqmath3/task1/eval.sh --nojudge",
        "cat ./eval-arqmath3/task1/result.tsv"
    ]
metrics = ["arqmath"]
